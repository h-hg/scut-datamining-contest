# -*- coding: utf-8 -*-
"""fasttext.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1awqWJiWI9s-delwkiTkRnJaBmu2NzWOs
"""

!pip install fasttext

!head -n 8000 train_5_label.txt > comment.train
!tail -n 2000 train_5_label.txt > comment.valid
!tail -n 500 train_5_label.txt > comment2.valid

import fasttext
import os
import sys
from sklearn import metrics


  
def print_results(N, p, r):
    print("N\t" + str(N))
    print("P@{}\t{:.3f}".format(1, p))
    print("R@{}\t{:.3f}".format(1, r))



if __name__ == '__main__':

    print("正在训练模型")
    model = fasttext.train_supervised(input = '/content/comment.train',epoch = 35,ws = 5, lr = 0.01, wordNgrams = 2, dim = 80,minCount = 1,loss = 'softmax')  # 模型自动以.bin后缀名保存
    print_results(*model.test('/content/comment.valid'))
    print(model.test_label('/content/comment.valid'))
    model.save_model('/content/model/fasttext_model.bin')
    print("训练完成")

print(model.test_label('/content/comment2.valid'))

!wget https://raw.githubusercontent.com/goto456/stopwords/master/%E7%99%BE%E5%BA%A6%E5%81%9C%E7%94%A8%E8%AF%8D%E8%A1%A8.txt

import jieba 
jieba.load_userdict('/content/userdict.txt')
with open('/content/stopWords.txt') as f:
    stopWords = [line.strip() for line in f.readlines()]

test_sentence = "有苍蝇。人都不好了 "
classifier = fasttext.load_model('/content/model/fasttext_model.bin')
predict_list = []
words = jieba.lcut(test_sentence)
words = [w for w in words if w not in stopWords]
print(words)
predict_list.append(' '.join(words))
pred = classifier.predict(predict_list)
print("分类为：" + str(pred))
#print(pred[0][0])
# 输出预测结果以及类别概率
#print(classifier.predict(test_sentence))

def predict_category(sentence):
    wl = jieba.lcut(sentence)
    wl = [w for w in wl if w not in stopWords]
    wl = ' '.join(wl)
    rs = classifier.predict(wl)
    #print("predict result: {}".format(rs))
    if rs[0][0] == '__label__1':
        return 1
    else:
        return 0

import csv
import pandas as pd
#file_object2=open('/content/test_new2.csv').read()  #一行行的读取内容
test_data = pd.read_csv('/content/test_fasttext.csv')
result = []
for index, row in test_data.iterrows():
    #print(index)
    result.append(predict_category(row["comment"]))
print(result)