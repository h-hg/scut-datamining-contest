# -*- coding: utf-8 -*-
"""CNNtext.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ySsP6YNIbjY501BP4K3ijpwkF0NjWH-M
"""

!pip install jieba
!pip install kashgari-tf

!head -n 8000 train_5_cnn.txt > comment_t.txt
!tail -n 2000 train_5_cnn.txt > comment_v_1.txt
!head -n 1500 comment_v_1.txt > comment_test.txt
!tail -n 500 comment_v_1.txt > comment_v.txt

import tqdm
import jieba

def read_data_file(path):
    lines = open(path, 'r', encoding='utf-8').read().splitlines()
    x_list = []
    y_list = []
    for line in tqdm.tqdm(lines):
        rows = line.split(',')
        if len(rows) >= 2:
            y_list.append(rows[1])
            x_list.append(rows[0])
        else:
            print(rows)
    return x_list, y_list

test_x, test_y = read_data_file('/content/comment_test.txt')
train_x, train_y = read_data_file('/content/comment_t.txt')
val_x, val_y = read_data_file('/content/comment_v.txt')

print(train_x[1:2])
# print(train_y[1:4])
#print(len(train_x))

from kashgari.tasks.classification import CNN_Model
from kashgari.tasks.classification import CNN_GRU_Model
from kashgari.tasks.classification import KMax_CNN_Model
from kashgari.tasks.classification import BiLSTM_Model
from kashgari.tasks.classification import AVCNN_Model
from kashgari.tasks.classification import AVRNN_Model
#model = CNN_GRU_Model()
model = AVRNN_Model()
model.fit(train_x, train_y, test_x, test_y, batch_size=1024,epochs = 15)

model.evaluate(val_x, val_y)

model.save('./model')

# new_model = CNNModel.load_model('./model')
# news = """「DeepMind 击败人类职业玩家的方式与他们声称的 AI 使命，以及所声称的『正确』方式完全相反。」
# DeepMind 的人工智能 AlphaStar 一战成名，击败两名人类职业选手。掌声和欢呼之余，它也引起了一些质疑。在前天 DeepMind 举办的 AMA 中，AlphaStar 项目领导者 Oriol Vinyals 和 David Silver、职业玩家 LiquidTLO 与 LiquidMaNa 回答了一些疑问。不过困惑依然存在……
# """
# x = list(jieba.cut(news))
# new_model.predict(x)

import jieba 
jieba.load_userdict('/content/userdict.txt')
with open('/content/stopWords.txt') as f:
    stopWords = [line.strip() for line in f.readlines()]

test_sentence = "有苍蝇。对一个才学了节肢动物的人来说，整个人都不好了 "
#classifier = CNNModel.load_model('./model')
predict_list = []
words = jieba.lcut(test_sentence)
words = [w for w in words if w not in stopWords]
print(words)
predict_list.append('\t'.join(words))
print(predict_list[0])
pred = model.predict(predict_list)
print(pred)
#print("分类为：" + str(pred))

def predict_category(sentence):
    wl = jieba.lcut(sentence)
    wl = [w for w in wl if w not in stopWords]
    wl = ' '.join(wl)
    rs = model.predict(wl)
    #print("predict result: {}".format(rs))
    return rs

import csv
import pandas as pd
#file_object2=open('/content/test_new2.csv').read()  #一行行的读取内容
test_data = pd.read_csv('/content/test_4.csv')
print(test_data.head())

result = []
predict_list2 = []
for index, row in test_data.iterrows():
    #print(index)
    #print(row["comment"])
    words = jieba.lcut(row["comment"])
    words = [w for w in words if w not in stopWords]
    #print(words)
    predict_list2.append('\t'.join(words))
    #result.append(predict_category(row["comment"]))
#print(result)
print(predict_list2[100:103])

result = model.predict(predict_list2)

print(f"{result}")