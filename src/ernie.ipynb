{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ernie.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"N8FRa6WwGUbg","colab_type":"code","colab":{}},"source":["!7z x \"/content/drive/My Drive/baidu_ernie.7z\" -r -o/content/baidu_ernie"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"u9rPTRUyfe_k","colab_type":"code","colab":{}},"source":["!7z x \"/content/drive/My Drive/chinese_roberta_wwm_large_ext_L-24_H-1024_A-16.zip\" -r -o/content/chinese_roberta_wwm_large_ext_L-24_H-1024_A-16"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FYikcML4GI1W","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GJeEDA2x6RgA","colab_type":"code","colab":{}},"source":["!mkdir models\n","!mkdir result\n","!mkdir data\n","!mkdir log"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"yv4p10gFITt4","colab_type":"code","colab":{}},"source":["!pip install keras_bert"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"baie1Og_F7It","colab_type":"code","outputId":"c55f00de-ae7e-45aa-da60-2deff17b0aa9","executionInfo":{"status":"ok","timestamp":1574434665271,"user_tz":-480,"elapsed":3047,"user":{"displayName":"Hunter Hwang","photoUrl":"","userId":"17918942437350807778"}},"colab":{"base_uri":"https://localhost:8080/","height":83}},"source":["import json\n","import numpy as np\n","from tqdm import tqdm\n","import time\n","import logging\n","from sklearn.model_selection import StratifiedKFold\n","from keras_bert import load_trained_model_from_checkpoint, Tokenizer\n","from keras.optimizers import Adam\n","import keras.backend.tensorflow_backend as KTF\n","import tensorflow as tf\n","import os\n","import pandas as pd\n","import re\n","import jieba\n","from keras.utils.np_utils import to_categorical\n","from sklearn.metrics import mean_absolute_error, accuracy_score, f1_score, roc_auc_score\n","import sys\n","import ipykernel"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"Z4FD99JgGArf","colab_type":"code","colab":{}},"source":["pd.set_option('display.max_columns', None)\n","\n","learning_rate = 5e-5\n","min_learning_rate = 2e-5\n","\n","base = '/content/baidu_ernie/'\n","config_path = base + 'bert_config.json'\n","checkpoint_path = base + 'bert_model.ckpt'\n","dict_path = base + 'vocab.txt'\n","# MAX_LEN = 30\n","MAX_LEN = 200"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MHa39wR0GC0Y","colab_type":"code","colab":{}},"source":["token_dict = {}\n","with open(dict_path, 'r', encoding='utf-8') as reader:\n","    for line in reader:\n","        token = line.strip()\n","        token_dict[token] = len(token_dict)\n","tokenizer = Tokenizer(token_dict)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QhUlIFduHBwG","colab_type":"code","colab":{}},"source":["file_path = '/content/log/'\n","# 创建一个logger\n","logger = logging.getLogger('mylogger')\n","logger.setLevel(logging.DEBUG)\n","\n","train = pd.read_csv('/content/data/train_bert_remove.csv')\n","test = pd.read_csv('/content/data/test_bert_remove.csv')\n","sub = pd.read_csv('/content/data/sample.csv')\n","\n","train_comment = train['comment'].values\n","test_comment = test['comment'].values\n","\n","labels = train['label'].astype(int).values"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IdK8olQ2HFtW","colab_type":"code","colab":{}},"source":["def seq_padding(X, padding=0):\n","    L = [len(x) for x in X]\n","    ML = max(L)\n","    return np.array([\n","        np.concatenate([x, [padding] * (ML - len(x))]) if len(x) < ML else x for x in X\n","    ])\n","\n","\n","class data_generator:\n","    def __init__(self, data, batch_size=8):\n","        self.data = data\n","        self.batch_size = batch_size\n","        self.steps = len(self.data[0]) // self.batch_size\n","        if len(self.data[0]) % self.batch_size != 0:\n","            self.steps += 1\n","\n","    def __len__(self):\n","        return self.steps\n","\n","    def __iter__(self):\n","        while True:\n","            X, y = self.data\n","\n","            idxs = list(range(len(self.data[0])))\n","            np.random.shuffle(idxs)\n","            T, T_, Y = [], [], []\n","            for c, i in enumerate(idxs):\n","                d = X[i]\n","                text = d[:MAX_LEN]\n","                t, t_ = tokenizer.encode(first=text)\n","                T.append(t)\n","                T_.append(t_)\n","                Y.append(y[i])\n","                if len(T) == self.batch_size or i == idxs[-1]:\n","                    Y = np.array(Y)\n","                    T = seq_padding(T)\n","                    T_ = seq_padding(T_)\n","                    yield [T, T_], Y\n","                    T, T_, Y = [], [], []\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"elWzECpjHWbV","colab_type":"code","colab":{}},"source":["from keras.layers import *\n","from keras.models import Model\n","import keras.backend as K\n","from keras.callbacks import Callback"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JZB9uHUnHYWZ","colab_type":"code","colab":{}},"source":["def get_model():\n","    bert_model = load_trained_model_from_checkpoint(config_path, checkpoint_path)\n","    for l in bert_model.layers:\n","        l.trainable = True\n","\n","    T1 = Input(shape=(None,))\n","    T2 = Input(shape=(None,))\n","\n","    T = bert_model([T1, T2])\n","\n","    T = Lambda(lambda x: x[:, 0])(T)\n","\n","    output = Dense(1, activation='sigmoid')(T)\n","\n","    model = Model([T1, T2], output)\n","    model.compile(\n","        loss='binary_crossentropy',\n","        optimizer=Adam(2e-5),  # 用足够小的学习率\n","        metrics=['accuracy']\n","    )\n","    model.summary()\n","    return model\n","\n","\n","class Evaluate(Callback):\n","    def __init__(self, val_data, val_index):\n","        self.score = []\n","        self.best = 0.\n","        self.early_stopping = 0\n","        self.val_data = val_data\n","        self.val_index = val_index\n","        self.predict = []\n","        self.lr = 0\n","        self.passed = 0\n","\n","    def on_batch_begin(self, batch, logs=None):\n","        \"\"\"第一个epoch用来warmup，第二个epoch把学习率降到最低\n","        \"\"\"\n","        if self.passed < self.params['steps']:\n","            self.lr = (self.passed + 1.) / self.params['steps'] * learning_rate\n","            K.set_value(self.model.optimizer.lr, self.lr)\n","            self.passed += 1\n","        elif self.params['steps'] <= self.passed < self.params['steps'] * 2:\n","            self.lr = (2 - (self.passed + 1.) / self.params['steps']) * (learning_rate - min_learning_rate)\n","            self.lr += min_learning_rate\n","            K.set_value(self.model.optimizer.lr, self.lr)\n","            self.passed += 1\n","\n","    def on_epoch_end(self, epoch, logs=None):\n","        score, acc, f1 = self.evaluate()\n","        if score > self.best:\n","            self.best = score\n","            self.early_stopping = 0\n","            model.save_weights('/content/models/bert{}.w'.format(fold))\n","        else:\n","            self.early_stopping += 1\n","        logger.info('lr: %.6f, epoch: %d, score: %.4f, acc: %.4f, f1: %.4f,best: %.4f\\n' % (\n","            self.lr, epoch, score, acc, f1, self.best))\n","\n","    def evaluate(self):\n","        self.predict = []\n","        prob = []\n","        val_x1, val_y = self.val_data\n","        for i in tqdm(range(len(val_x1))):\n","            d = val_x1[i]\n","            text = d[:MAX_LEN]\n","\n","            t1, t1_ = tokenizer.encode(first=text)\n","            T1, T1_ = np.array([t1]), np.array([t1_])\n","            _prob = model.predict([T1, T1_])\n","            oof_train[self.val_index[i]] = _prob[0]\n","            self.predict.append(np.argmax(_prob, axis=1)[0] + 1)\n","            prob.append(_prob[0])\n","\n","        score = 1.0 / (1 + mean_absolute_error(val_y + 1, self.predict))\n","        acc = accuracy_score(val_y + 1, self.predict)\n","        f1 = f1_score(val_y + 1, self.predict, average='macro',labels=np.unique(self.predict))\n","        return score, acc, f1\n","\n","\n","skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n","\n","\n","def predict(data):\n","    prob = []\n","    val_x1 = data\n","    for i in tqdm(range(len(val_x1))):\n","        X = val_x1[i]\n","        text = X[:MAX_LEN]\n","        t1, t1_ = tokenizer.encode(first=text)\n","        T1, T1_ = np.array([t1]), np.array([t1_])\n","        _prob = model.predict([T1, T1_])\n","        prob.append(_prob[0])\n","    return prob\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"LJi1-BAiHdeD","colab_type":"code","outputId":"b2ce1048-5b16-4962-fed2-29e70005d9eb","executionInfo":{"status":"ok","timestamp":1574444717093,"user_tz":-480,"elapsed":9942213,"user":{"displayName":"Hunter Hwang","photoUrl":"","userId":"17918942437350807778"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["oof_train = np.zeros((len(train), 1), dtype=np.float32)\n","oof_test = np.zeros((len(test), 1), dtype=np.float32)\n","for fold, (train_index, valid_index) in enumerate(skf.split(train_comment, labels)):\n","    logger.info('================     fold {}        ==============='.format(fold))\n","    x1 = train_comment[train_index]\n","    y = labels[train_index]\n","\n","    val_x1 = train_comment[valid_index]\n","    val_y = labels[valid_index]\n","\n","    train_D = data_generator([x1, y])\n","    evaluator = Evaluate([val_x1, val_y], valid_index)\n","\n","    model = get_model()\n","    model.fit_generator(train_D.__iter__(),\n","                        steps_per_epoch=len(train_D),\n","                        epochs=4,\n","                        callbacks=[evaluator]\n","                        )\n","    model.load_weights('/content/models/bert{}.w'.format(fold))\n","    oof_test += predict(test_comment)\n","    K.clear_session()\n","    test['flag'] = oof_test\n","\n","oof_test /= 4\n","\n","np.savetxt('/content/models/train_bert.txt', oof_train)\n","np.savetxt('/content/test_bert.txt', oof_test)\n","\n","oof_train = oof_train.reshape(-1)\n","cv_score = roc_auc_score(labels, oof_train)\n","print(cv_score)\n","\n","test['flag'] = oof_test\n","test['flag'] = test['flag'].apply(lambda x: 0 if x < 0.5 else 1)\n","test[['id', 'flag']].to_csv('/content/result/bert_{}.csv'.format(cv_score), index=False)\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4479: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","Model: \"model_3\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            (None, None)         0                                            \n","__________________________________________________________________________________________________\n","input_2 (InputLayer)            (None, None)         0                                            \n","__________________________________________________________________________________________________\n","model_2 (Model)                 multiple             99275520    input_1[0][0]                    \n","                                                                 input_2[0][0]                    \n","__________________________________________________________________________________________________\n","lambda_1 (Lambda)               (None, 768)          0           model_2[1][0]                    \n","__________________________________________________________________________________________________\n","dense_1 (Dense)                 (None, 1)            769         lambda_1[0][0]                   \n","==================================================================================================\n","Total params: 99,276,289\n","Trainable params: 99,276,289\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n","\n","Epoch 1/4\n","1000/1000 [==============================] - 432s 432ms/step - loss: 0.1451 - acc: 0.9432\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 2001/2001 [00:54<00:00, 40.08it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 2/4\n","1000/1000 [==============================] - 415s 415ms/step - loss: 0.0581 - acc: 0.9800\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 2001/2001 [00:49<00:00, 40.10it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 3/4\n","1000/1000 [==============================] - 412s 412ms/step - loss: 0.0173 - acc: 0.9945\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 2001/2001 [00:49<00:00, 40.65it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 4/4\n","1000/1000 [==============================] - 410s 410ms/step - loss: 0.0102 - acc: 0.9969\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 2001/2001 [00:48<00:00, 41.43it/s]\n","100%|██████████| 2000/2000 [00:50<00:00, 41.98it/s]"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:107: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"stream","text":["Model: \"model_3\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            (None, None)         0                                            \n","__________________________________________________________________________________________________\n","input_2 (InputLayer)            (None, None)         0                                            \n","__________________________________________________________________________________________________\n","model_2 (Model)                 multiple             99275520    input_1[0][0]                    \n","                                                                 input_2[0][0]                    \n","__________________________________________________________________________________________________\n","lambda_1 (Lambda)               (None, 768)          0           model_2[1][0]                    \n","__________________________________________________________________________________________________\n","dense_1 (Dense)                 (None, 1)            769         lambda_1[0][0]                   \n","==================================================================================================\n","Total params: 99,276,289\n","Trainable params: 99,276,289\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","Epoch 1/4\n","1000/1000 [==============================] - 440s 440ms/step - loss: 0.1642 - acc: 0.9347\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 2000/2000 [00:53<00:00, 37.07it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 2/4\n","1000/1000 [==============================] - 421s 421ms/step - loss: 0.0643 - acc: 0.9782\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 2000/2000 [00:49<00:00, 40.26it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 3/4\n","1000/1000 [==============================] - 417s 417ms/step - loss: 0.0260 - acc: 0.9911\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 2000/2000 [00:48<00:00, 38.32it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 4/4\n","1000/1000 [==============================] - 420s 420ms/step - loss: 0.0078 - acc: 0.9971\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 2000/2000 [00:50<00:00, 39.35it/s]\n","100%|██████████| 2000/2000 [00:50<00:00, 39.99it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Model: \"model_3\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            (None, None)         0                                            \n","__________________________________________________________________________________________________\n","input_2 (InputLayer)            (None, None)         0                                            \n","__________________________________________________________________________________________________\n","model_2 (Model)                 multiple             99275520    input_1[0][0]                    \n","                                                                 input_2[0][0]                    \n","__________________________________________________________________________________________________\n","lambda_1 (Lambda)               (None, 768)          0           model_2[1][0]                    \n","__________________________________________________________________________________________________\n","dense_1 (Dense)                 (None, 1)            769         lambda_1[0][0]                   \n","==================================================================================================\n","Total params: 99,276,289\n","Trainable params: 99,276,289\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","Epoch 1/4\n","1000/1000 [==============================] - 435s 435ms/step - loss: 0.1606 - acc: 0.9354\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 2000/2000 [00:51<00:00, 42.49it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 2/4\n","1000/1000 [==============================] - 415s 415ms/step - loss: 0.0680 - acc: 0.9768\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 2000/2000 [00:51<00:00, 39.16it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 3/4\n","1000/1000 [==============================] - 414s 414ms/step - loss: 0.0258 - acc: 0.9904\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 2000/2000 [00:48<00:00, 41.14it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 4/4\n","1000/1000 [==============================] - 414s 414ms/step - loss: 0.0104 - acc: 0.9970\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 2000/2000 [00:50<00:00, 39.60it/s]\n","100%|██████████| 2000/2000 [00:49<00:00, 40.49it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Model: \"model_3\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            (None, None)         0                                            \n","__________________________________________________________________________________________________\n","input_2 (InputLayer)            (None, None)         0                                            \n","__________________________________________________________________________________________________\n","model_2 (Model)                 multiple             99275520    input_1[0][0]                    \n","                                                                 input_2[0][0]                    \n","__________________________________________________________________________________________________\n","lambda_1 (Lambda)               (None, 768)          0           model_2[1][0]                    \n","__________________________________________________________________________________________________\n","dense_1 (Dense)                 (None, 1)            769         lambda_1[0][0]                   \n","==================================================================================================\n","Total params: 99,276,289\n","Trainable params: 99,276,289\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","Epoch 1/4\n","1000/1000 [==============================] - 445s 445ms/step - loss: 0.1503 - acc: 0.9380\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 2000/2000 [00:52<00:00, 37.79it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 2/4\n","1000/1000 [==============================] - 424s 424ms/step - loss: 0.0642 - acc: 0.9788\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 2000/2000 [00:50<00:00, 39.90it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 3/4\n","1000/1000 [==============================] - 422s 422ms/step - loss: 0.0187 - acc: 0.9942\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 2000/2000 [00:50<00:00, 39.31it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 4/4\n","1000/1000 [==============================] - 422s 422ms/step - loss: 0.0093 - acc: 0.9970\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 2000/2000 [00:51<00:00, 39.04it/s]\n","100%|██████████| 2000/2000 [00:50<00:00, 39.75it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Model: \"model_3\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            (None, None)         0                                            \n","__________________________________________________________________________________________________\n","input_2 (InputLayer)            (None, None)         0                                            \n","__________________________________________________________________________________________________\n","model_2 (Model)                 multiple             99275520    input_1[0][0]                    \n","                                                                 input_2[0][0]                    \n","__________________________________________________________________________________________________\n","lambda_1 (Lambda)               (None, 768)          0           model_2[1][0]                    \n","__________________________________________________________________________________________________\n","dense_1 (Dense)                 (None, 1)            769         lambda_1[0][0]                   \n","==================================================================================================\n","Total params: 99,276,289\n","Trainable params: 99,276,289\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","Epoch 1/4\n","1001/1001 [==============================] - 437s 437ms/step - loss: 0.1742 - acc: 0.9263\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 1999/1999 [00:49<00:00, 40.41it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 2/4\n","1001/1001 [==============================] - 415s 414ms/step - loss: 0.0582 - acc: 0.9778\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 1999/1999 [00:47<00:00, 42.25it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 3/4\n","1001/1001 [==============================] - 415s 415ms/step - loss: 0.0214 - acc: 0.9915\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 1999/1999 [00:46<00:00, 42.56it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 4/4\n","1001/1001 [==============================] - 414s 414ms/step - loss: 0.0107 - acc: 0.9959\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 1999/1999 [00:48<00:00, 40.84it/s]\n","100%|██████████| 2000/2000 [00:50<00:00, 39.98it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["0.9891169161258946\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"XocbzTa5NT8Y","colab_type":"text"},"source":[""]}]}